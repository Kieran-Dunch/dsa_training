// Asymptotic Notation refers to the mathematical notation used to describe the
// running time of an algorithm when the input tends towards a particular value
// or a limiting value.

// Big O Notation
// Big O notation is used to describe the performance or complexity of an
// algorithm. Big O specifically describes the worst-case scenario, and can be
// used to describe the execution time required or the space used (e.g. in
// memory or on disk) by an algorithm.

// O(1) describes an algorithm that will always execute in the same time
// (or space) regardless of the size of the input data set.

// O(N) describes an algorithm whose performance will grow linearly and in
// direct proportion to the size of the input data set. The example below also
// demonstrates how Big O favours the worst-case performance scenario; a matching
// string could be found during any iteration of the for loop and the function
// would return early, but Big O notation will always assume the upper limit
// where the algorithm will perform the maximum number of iterations.
